{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mrrs08JS75T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.style.use('./deeplearning.mplstyle')\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from sklearn.datasets import make_blobs\n",
        "# %matplotlib widget\n",
        "# from matplotlib.widgets import Slider\n",
        "# from lab_utils_common import dlc\n",
        "# from lab_utils_softmax import plt_softmax\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softmax(z):\n",
        "    ez = np.exp(z)              #element-wise exponenial\n",
        "    sm = ez/np.sum(ez)\n",
        "    return(sm)"
      ],
      "metadata": {
        "id": "oFEix0i6TFbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make  dataset for example\n",
        "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
        "X_train, y_train = make_blobs(n_samples=2000, centers=centers, cluster_std=1.0,random_state=30)"
      ],
      "metadata": {
        "id": "m7Bnb_UWTXRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NexxEfC6UH4o",
        "outputId": "8cfc3f4b-55d0-4fb8-ea2c-140c6e7d1161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.55508243  0.84801682]\n",
            " [-5.33749882  1.03397255]\n",
            " [-4.09353183  0.67843096]\n",
            " ...\n",
            " [-0.84437575 -1.94991543]\n",
            " [ 5.0377068  -2.92221685]\n",
            " [ 0.38198674  1.49735733]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xK1G5NkUMqt",
        "outputId": "de82b4b0-cd53-4c87-bb8c-07d57ea03679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 0 0 ... 1 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "\n",
        "        tf.keras.layers.Dense(units=25,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(units=15,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(units=4,activation=\"softmax\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "e6Y3qC9wUPR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(0.01),\n",
        ")\n",
        "\n",
        "model.fit(X_train,y_train,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJnhVP9JVBZl",
        "outputId": "3e328470-f174-4d57-d56f-17a13181b24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 1s 2ms/step - loss: 0.1729\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0377\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0278\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0211\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0205\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0228\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0163\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0173\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0195\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0201\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0179\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0156\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0180\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0150\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0210\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0185\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0210\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0227\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0145\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0189\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0161\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0184\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0155\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0147\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0171\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0167\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0162\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0138\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0152\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0244\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0129\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0192\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0170\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0194\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0198\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0130\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0136\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0113\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0123\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0147\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0144\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0187\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0256\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0177\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0150\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0261\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0288\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0149\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0132\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0123\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0114\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0146\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0111\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0130\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0143\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0207\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0184\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0131\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0131\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0160\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0120\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0123\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0127\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0148\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0115\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0155\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0145\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0105\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0116\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0095\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0121\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0129\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0102\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0100\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0142\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0130\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0107\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0125\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0095\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0104\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0108\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0112\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0183\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0152\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0127\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0258\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0182\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c79207cc9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_nonpreferred = model.predict(X_train)\n",
        "print(p_nonpreferred [:2])\n",
        "print(\"largest value\", np.max(p_nonpreferred), \"smallest value\", np.min(p_nonpreferred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqnS_13rVjUl",
        "outputId": "a5f137db-2c9e-4b2f-ceb7-d984da9646c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "[[2.6745795e-06 7.7534512e-09 9.9999720e-01 8.0958742e-09]\n",
            " [9.9999994e-01 2.5496244e-10 1.1290312e-09 1.7647940e-17]]\n",
            "largest value 0.99999994 smallest value 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preferred_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(25, activation = 'relu'),\n",
        "        tf.keras.layers.Dense(15, activation = 'relu'),\n",
        "        tf.keras.layers.Dense(4, activation = 'linear')   #<-- Note\n",
        "    ]\n",
        ")\n",
        "preferred_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #<-- Note\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        ")\n",
        "\n",
        "preferred_model.fit(\n",
        "    X_train,y_train,\n",
        "    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btwp9MhbVxaG",
        "outputId": "537ffc93-8edc-4dda-fac1-af2db8a7d7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 1s 2ms/step - loss: 1.3737\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.5357\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.2626\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1544\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.1074\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0842\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0706\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.0563\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0514\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c791d24b8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_preferred = preferred_model.predict(X_train)\n",
        "print(f\"two example output vectors:\\n {p_preferred[:2]}\")\n",
        "print(\"largest value\", np.max(p_preferred), \"smallest value\", np.min(p_preferred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3e0plv3WAdZ",
        "outputId": "7662d915-56ce-43fe-850c-c52294eed3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "two example output vectors:\n",
            " [[-0.5855501  -1.1746771   4.599722    1.4259931 ]\n",
            " [ 6.922118    2.396075   -0.99896437 -5.9413185 ]]\n",
            "largest value 14.404421 smallest value -9.154756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_preferred = tf.nn.softmax(p_preferred).numpy()\n",
        "print(f\"two example output vectors:\\n {sm_preferred[:2]}\")\n",
        "print(\"largest value\", np.max(sm_preferred), \"smallest value\", np.min(sm_preferred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUItW71xWKjX",
        "outputId": "4d0574af-1610-4bfe-95c5-9dee9a6e90c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two example output vectors:\n",
            " [[5.3290213e-03 2.9566034e-03 9.5188081e-01 3.9833605e-02]\n",
            " [9.8893481e-01 1.0703657e-02 3.5899240e-04 2.5624070e-06]]\n",
            "largest value 0.9999886 smallest value 4.7269794e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print( f\"{p_preferred[i]}, category: {np.argmax(p_preferred[i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMsHXg7xWWSa",
        "outputId": "aa60cd51-1349-4cd0-d8c2-1ceecd99b81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.5855501 -1.1746771  4.599722   1.4259931], category: 2\n",
            "[ 6.922118    2.396075   -0.99896437 -5.9413185 ], category: 0\n",
            "[ 5.1077538  2.233546  -0.8733397 -4.719685 ], category: 0\n",
            "[-0.83863556  3.9463406  -1.997936   -1.1608766 ], category: 1\n",
            "[ 2.4017465 -1.7322303  6.843753  -1.0289676], category: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkwPibQiWaMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}